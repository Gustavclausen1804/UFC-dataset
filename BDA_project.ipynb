{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ ME\n",
    "This is a final project for the course 'Business Data Analytics, Quantitative Methods and Visualization' (2021, Copenhagen Business School).\n",
    "The goal of this project is to be able to predict the outcome of a certain UFC fight, more specifically to predict whether the Red or Blue fighter is more likely to win the match.\n",
    "\n",
    "We are going to do this through the following steps:\n",
    "1. __Importing necessary libraries and tools.__\n",
    "2. __Loading, Cleaning & Exploring the dataset.__\n",
    "3. __Data pre-processing.__\n",
    "4. __Machine Learning Models.__\n",
    "5. __Making a prediction.__\n",
    "6. __Showcasing results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legend\n",
    "\n",
    "- ufc = the original dataset\n",
    "- column_names = list of column names\n",
    "- ufc_df = the dataset without NaNs\n",
    "- datatypes = dictionary with column names + their datatypes\n",
    "- ufc_ohe = one hot encoded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing necessary libraries and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd #used\n",
    "import matplotlib.pyplot as plt #used\n",
    "import numpy as np #used\n",
    "import seaborn as sns #used\n",
    "\n",
    "# models\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier #used\n",
    "from sklearn.neural_network import MLPClassifier #used\n",
    "from sklearn.tree import DecisionTreeClassifier #used\n",
    "from sklearn.ensemble import RandomForestClassifier #used\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #used\n",
    "from sklearn.feature_selection import SelectKBest #used\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# use cross validation with grid search as well. \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# other tools\n",
    "\n",
    "from sklearn.model_selection import train_test_split #used\n",
    "from sklearn.metrics import accuracy_score #used\n",
    "\n",
    "import warnings #used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading, Cleaning & Exploring the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load excel file (ufc.xlsx) and print out the first couple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc = pd.read_excel('newestdataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of rows:', ufc.shape[0])\n",
    "# print('Number of columns:', ufc.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Get the list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ufc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *We can call this list whenever we want to check the name of a column.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ufc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, there are some NaNs in these columns that should later be taken care of:\n",
    "- B_avg_SIG_STR_landed\n",
    "- B_avg_SIG_STR_pct\n",
    "- B_avg_SUB_ATT     \n",
    "- B_avg_TD_landed      \n",
    "- B_avg_TD_pct\n",
    "- R_avg_SIG_STR_landed\n",
    "- R_avg_SIG_STR_pct\n",
    "- R_avg_SUB_ATT     \n",
    "- R_avg_TD_landed      \n",
    "- R_avg_TD_pct  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = ufc.duplicated()\n",
    "ufc[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *It seems that there are no duplicates, therefore, we only need to focus on NaN values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Fill NaNs with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df = ufc.fillna(0)\n",
    "\n",
    "print('Number of rows:', ufc_df.shape[0])\n",
    "print('Number of columns:', ufc_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Check if columns have the right datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes = ufc_df.dtypes.to_dict()\n",
    "# datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O = object\n",
    "- int64 = integer\n",
    "- float64 = float\n",
    "- <M8[ns] = date (\"On a machine whose byte order is little endian, there is no difference between *np.dtype('datetime64[ns]')* and *np.dtype('<M8[ns]')*\")\n",
    "- bool = True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Fix datatypes if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Use info() again to check missing values and datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Create a dataframes for visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General features\n",
    "ufc_gen = ufc_df[['R_odds_dec', 'B_odds_dec', 'date', 'location', 'Winner', 'weight_class', 'Reach_diff_ins', 'Age_diff']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Use head() for a better overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 General features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12.1 Odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ufc_gen[['R_odds_dec', 'B_odds_dec']], color = ['Red', 'Blue'], bins = 6, orientation = 'horizontal', label = ['Red fighter', 'Blue fighter'])\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Odds')\n",
    "plt.title('Freqency of different odds, divided between Red and Blue fighters.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The graph basically shows that there were approximately 2400 fights where the Red Fighter's odds were around 1-2, while there were only around 1900 where Blue Fighters had such a low odds (which means higher chance to win). However, in case of higher odds (which means less chance of winning the fight) Blue Fighters are dominating.* \n",
    "\n",
    "*From these, we can see that Red Fighters have lower odds in general which proves that statistically, they have higher chances to win. This seems logical as Red fighters are usually Favorites and Blue Fighters are underdogs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12.2 Location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_gen['location'].value_counts().head(10).sort_values(ascending = True).plot(kind = 'barh', color = 'Lightgrey')\n",
    "plt.xlabel('Number of fights')\n",
    "plt.title('10 locations with the most fights.')\n",
    "plt.savefig('location.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Seems skewed, it's worth considering leaving location out.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12.3 Winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(ufc_gen['Winner'], palette = ['Red', 'Blue', 'Lightgrey'])\n",
    "\n",
    "for rect in ax.patches:\n",
    "    ax.text (rect.get_x() + rect.get_width()  / 2,rect.get_height()+ 0.75,rect.get_height(), ha = 'center', va = 'baseline', color = 'black', size = 12\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_gen['Winner'].value_counts().plot.pie(colors = ['Red', 'Blue', 'Lightgrey'], \n",
    "                labels=['Red fighter won', 'Blue fighter won', 'Draw'], autopct='%.1f%%', figsize = (7,7))\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution (in %) of Outcomes of the Fights.')\n",
    "plt.savefig('piechart.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Based on the 2 graphs above, we can say that Red Fighters win more often which is probably because the Red Fighter is the Favorite.*\n",
    "\n",
    "*If 56.2% of UFC fights end with a Red-win, one could say that he should always bet on the Red Fighter for higher chances.*\n",
    "\n",
    "*Our goal is to exceed that 56.2% with our machine learning algorithm, and to be able to make more exact and appropiate decisions.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12.4 Weight class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would be nice to divide it to two graphs by gender\n",
    "\n",
    "ufc_gen.groupby('weight_class').mean().plot.bar(figsize=(20,5), color = ['Red', 'Blue', 'Lightgrey', 'Grey', 'Black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *We can see that the features included in this visualization highly depend on what weight class we are talking about, therefore, we should definetely include 'weight_class' in our most important features.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12.5 Reach & Age Difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "ufc_gen.Age_diff.hist(bins = 40, color = 'grey')\n",
    "plt.xlabel('Age difference')\n",
    "plt.ylabel('Number of Fights')\n",
    "plt.title('Number of Fights with various Age differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "ufc_gen.Reach_diff_ins.hist(bins = 40, color = 'grey')\n",
    "plt.xlabel('Reach difference (inch)')\n",
    "plt.ylabel('Number of Fights')\n",
    "plt.title('Number of Fights with various Reach differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Similar curve, similar values - wouldn't it be enough to include only one of them (either age or reach difference)?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Fighter Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = ['B_current_lose_streak', 'B_current_win_streak', 'B_total_SIG_STR_landed',\n",
    "                'B_avg_SIG_STR_landed_per_fight', 'B_losses', 'B_total_title_bouts',\n",
    "                 'B_wins', 'B_Height_cms', 'B_Reach_ins', 'B_UFC_fights', 'B_age', 'B_Reach_cms', 'R_current_lose_streak',\n",
    "                 'R_current_win_streak', 'R_total_SIG_STR_landed', 'R_avg_SIG_STR_landed_per_fight', 'R_losses',\n",
    "                 'R_total_title_bouts', 'R_wins', 'R_Height_cms', 'R_Reach_ins', 'R_UFC_fights', 'R_age', 'R_Reach_cms',\n",
    "                 'Reach_diff_ins', 'Age_diff']\n",
    "corr = ufc_df[corr_features].corr(method='pearson')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "cmap = sns.color_palette(\"crest\", as_cmap=True)\n",
    "sns.heatmap(corr, square= True, annot = True, cmap = cmap)\n",
    "plt.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- height & reach are highly correlated, we could keep only one of them (as we included reach difference, i think we should keep reach difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Drop unnecessary columns & drop fights that ended in a draw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df = ufc_df.drop(labels = ['R_fighter', 'B_fighter', 'location',\n",
    "       'Referee', 'date', 'R_odds', 'B_odds', 'R_Weight_lbs', 'B_Weight_lbs', 'no_of_rounds'], axis = 1)\n",
    "\n",
    "ufc_df = ufc_df.drop(ufc_df[ufc_df.Winner == 'Draw'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Deal with nominal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "onehot_columns = ['weight_class', 'R_Stance', 'B_Stance']\n",
    "\n",
    "ufc_ohe = pd.get_dummies(ufc_df, columns = onehot_columns, drop_first=True)\n",
    "ufc_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ufc_ohe[['title_bout',\n",
    "       'B_current_lose_streak', 'B_current_win_streak', 'B_avg_KD', 'B_SLpM',\n",
    "       'B_SApM', 'B_Sd', 'B_total_SIG_STR_landed',\n",
    "       'B_avg_SIG_STR_landed_per_fight', 'B_losses',\n",
    "       'B_avg_SIG_STR_absorberd_per_fight', 'B_total_SIG_STR_absorbed',\n",
    "       'B_avg_opp_TOTAL_STR_landed', 'B_total_rounds_fought',\n",
    "       'B_total_time_fought(minutes)', 'B_total_time_fought(seconds)',\n",
    "       'B_avg_time_fought_per_fight(seconds)', 'B_total_title_bouts',\n",
    "       'B_win_by_Decision_Majority', 'B_win_by_Decision_Split',\n",
    "       'B_win_by_Decision_Unanimous', 'B_win_by_KO/TKO', 'B_win_by_Submission',\n",
    "       'B_win_by_TKO_Doctor_Stoppage', 'B_wins', 'B_Height_cms', 'B_Reach_ins',\n",
    "       'B_UFC_fights', 'B_age', 'B_Reach_cms', 'R_current_lose_streak',\n",
    "       'R_current_win_streak', 'R_avg_KD', 'R_SLpM', 'R_SApM', 'R_Sd',\n",
    "       'R_total_SIG_STR_absorbed', 'R_total_SIG_STR_landed',\n",
    "       'R_avg_SIG_STR_landed_per_fight', 'R_losses',\n",
    "       'R_avg_SIG_STR_absorbed_per_fight', 'R_avg_opp_TOTAL_STR_landed',\n",
    "       'R_total_rounds_fought', 'R_total_time_fought(minutes)',\n",
    "       'R_total_time_fought(seconds)', 'R_avg_time_fought_per_fight(seconds)',\n",
    "       'R_total_title_bouts', 'R_win_by_Decision_Majority',\n",
    "       'R_win_by_Decision_Split', 'R_win_by_Decision_Unanimous',\n",
    "       'R_win_by_KO/TKO', 'R_win_by_Submission',\n",
    "       'R_win_by_TKO_Doctor_Stoppage', 'R_wins', 'R_Height_cms', 'R_Reach_ins',\n",
    "       'R_Reach_cms', 'R_UFC_fights', 'R_age', 'Reach_diff_ins', 'Age_diff',\n",
    "       'weight_class_Catch Weight', 'weight_class_Featherweight',\n",
    "       'weight_class_Flyweight', 'weight_class_Heavyweight',\n",
    "       'weight_class_Light Heavyweight', 'weight_class_Lightweight',\n",
    "       'weight_class_Middleweight', 'weight_class_Open Weight',\n",
    "       'weight_class_Welterweight', 'weight_class_Women\\'s Bantamweight',\n",
    "       'weight_class_Women\\'s Featherweight', 'weight_class_Women\\'s Flyweight',\n",
    "       'weight_class_Women\\'s Strawweight', 'R_Stance_Open Stance',\n",
    "       'R_Stance_Orthodox', 'R_Stance_Sideways', 'R_Stance_Southpaw',\n",
    "       'R_Stance_Switch', 'B_Stance_Open Stance', 'B_Stance_Orthodox',\n",
    "       'B_Stance_Sideways', 'B_Stance_Southpaw', 'B_Stance_Switch']]\n",
    "y = ufc_ohe['Winner']\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Select the 20 most influential features & select the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best features\n",
    "#print(X.shape)\n",
    "\n",
    "k_best = SelectKBest(k = 20)\n",
    "k_best.fit(X, y)\n",
    "X_train_k_best = k_best.transform(X)\n",
    "# X_test_k_best = k_best.transform(X)\n",
    "\n",
    "#print(X_train_k_best.shape)\n",
    "#print(X.columns[k_best.get_support()])\n",
    "\n",
    "best_features = X.columns[k_best.get_support()]\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X = ufc_ohe[best_features]\n",
    "y = ufc_ohe['Winner']\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Deal with numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_columns = ['B_current_lose_streak', 'B_current_win_streak', 'B_total_SIG_STR_landed',\n",
    "#                'B_avg_SIG_STR_landed_per_fight', 'B_losses', 'B_total_title_bouts',\n",
    "#                 'B_wins', 'B_Height_cms', 'B_Reach_ins', 'B_UFC_fights', 'B_age', 'B_Reach_cms', 'R_current_lose_streak',\n",
    "#                 'R_current_win_streak', 'R_total_SIG_STR_landed', 'R_avg_SIG_STR_landed_per_fight', 'R_losses',\n",
    "#                 'R_total_title_bouts', 'R_wins', 'R_Height_cms', 'R_Reach_ins', 'R_UFC_fights', 'R_age', 'R_Reach_cms',\n",
    "#                 'Reach_diff_ins', 'Age_diff']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Machine Learning Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# neural network\n",
    "mpl = MLPClassifier()\n",
    "\n",
    "# decision tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# random forest\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "classifiers = (knn, mpl, tree, forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Build the 'applyModel' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyModel(model,name,X_train, y_train, X_test, y_test):\n",
    "    m = model.fit(X_train,y_train)\n",
    "    print(name, '- Training accuracy:', m.score(X_train, y_train))\n",
    "    print(name, '- Testing accuracy:', m.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train and test with the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classifiers:\n",
    "    n = str(c)\n",
    "    applyModel(c, n, X_train, y_train, X_test, y_test)\n",
    "    print('')\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prinipal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained of the variance. We can see that the first explains most of the variance \n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = ['Red', 'Blue']\n",
    "colors = ['r', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['Winner'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap of components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = pd.DataFrame(pca.components_,columns=[best_features])\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(map,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the PCA model & transform the X_train & and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pca.transform(X_train)\n",
    "pca_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing neural network & Random Forest on PCA transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(alpha=4, learning_rate=\"invscaling\")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Decision KNeighborsClassifier, Cancer dataset, weights set to \"distance\", and 5 neighbors')\n",
    "print('Accuracy on the training set: {:.3f}'.format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy on test set: {:.3f}'.format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = RandomForestClassifier(max_depth=6, criterion='entropy')\n",
    "\n",
    "knn.fit(pca_train, y_train)\n",
    "\n",
    "print('Decision KNeighborsClassifier, Cancer dataset, weights set to \"distance\", and 5 neighbors')\n",
    "print('Accuracy on the training set: {:.3f}'.format(knn.score(pca_train, y_train)))\n",
    "print('Accuracy on test set: {:.3f}'.format(knn.score(pca_test, y_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are not satisfied with the accuracy & test score, so we do not continue using the PCA transformed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Play around with KNN on normal X_train,X_test, y_train, & y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "number_of_neighbors =[]\n",
    "weighting_choice = []\n",
    "\n",
    "weight_values = ['distance', 'uniform']\n",
    "\n",
    "for n_neighbors in range(1,100):\n",
    "    for weights in weight_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors = n_neighbors, weights = weights)\n",
    "        clf.fit(X_train, y_train)\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "        testing_accuracy.append(clf.score(X_test, y_test))\n",
    "        number_of_neighbors.append(n_neighbors)\n",
    "        weighting_choice.append(weights)\n",
    "      \n",
    "     \n",
    "combinations_sorted_knn = sorted(list(zip(number_of_neighbors, weighting_choice, training_accuracy, testing_accuracy)), key = lambda e:e[3], reverse = True)\n",
    "\n",
    "print('Top 5 results, sorted by test accuracy:\\n')\n",
    "print(*combinations_sorted_knn[0:5], sep = \"\\n\")\n",
    "\n",
    "# save the best variables\n",
    "knn_best_n_neighbors = combinations_sorted_knn[0][0]\n",
    "knn_best_weights = combinations_sorted_knn[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.1 KNN - Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the parameters which want to test for the KNN model\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [32,54,74,100], \"weights\": [\"uniform\", \"distance\"], \"metric\": [\"euclidean\", \"manhatten\"], \"leaf_size\": [10,30,60]\n",
    "}\n",
    "\n",
    "#We make the model with cross validation and grid search\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10)\n",
    "\n",
    "#We fit the model, with the best parameters: \n",
    "gs_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print the results: \n",
    "\n",
    "print(\n",
    "    \"\\n Training score: \", gs_result.best_score_, \n",
    "    \"\\n Best estimator: \", gs_result.best_estimator_\n",
    "    # ,\"\\n best parameters: \", gs_result.best_params_\n",
    ")\n",
    "\n",
    "print(\"Test score: \", grid_search.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Play around with Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "alpha_value = []\n",
    "learning_rate_value = []\n",
    "\n",
    "\n",
    "alphas = (0.0001, 0.001, 0.1, 0, 1, 5, 100)\n",
    "learning_rates = ('constant', 'invscaling', 'adaptive')\n",
    "\n",
    "for a in alphas:\n",
    "    for l in learning_rates:\n",
    "        mpl = MLPClassifier(alpha=a, learning_rate = l)\n",
    "        mpl.fit(X_train, y_train)\n",
    "        train_acc.append(accuracy_score(mpl.predict(X_train), y_train))\n",
    "        test_acc.append(accuracy_score(mpl.predict(X_test), y_test))\n",
    "        alpha_value.append(a)\n",
    "        learning_rate_value.append(l)\n",
    "        \n",
    "\n",
    "combinations_sorted_mpl = sorted(list(zip(alpha_value, learning_rate_value, train_acc, test_acc)), key = lambda e:e[3], reverse = True)\n",
    "\n",
    "print('Top 5 results, sorted by test accuracy:\\n')\n",
    "print(*combinations_sorted_mpl[0:5], sep = \"\\n\")\n",
    "\n",
    "# save the best variables\n",
    "mpl_best_alpha = combinations_sorted_knn[0][0]\n",
    "mpl_best_learning_rate = combinations_sorted_knn[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network - Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the parameters which want to test for the decision tree model\n",
    "param_grid = {\"learning_rate\":[\"constant\", \"invscaling\", \"adaptive\"], \"alpha\":[0.01,0.01,1,5,10,15]}\n",
    "\n",
    "#We make the model with cross validation and grid search\n",
    "grid_search = GridSearchCV(MLPClassifier(), param_grid, cv=10)\n",
    "\n",
    "#We fit the model, with the best parameters: \n",
    "gs_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print the results: \n",
    "\n",
    "print(\n",
    "    \"\\n Training score: \", gs_result.best_score_, \n",
    "    \"\\n Best estimator: \", gs_result.best_estimator_,\n",
    "    \"\\n best parameters: \", gs_result.best_params_,\n",
    "    \"Test score: \", grid_search.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Play around with Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "max_depth_value = []\n",
    "\n",
    "for i in range(1,30):\n",
    "    dt = DecisionTreeClassifier(max_depth = i, random_state=0)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_acc.append(accuracy_score(dt.predict(X_train), y_train))\n",
    "    test_acc.append(accuracy_score(dt.predict(X_test), y_test))\n",
    "    max_depth_value.append(i)\n",
    "\n",
    "combinations_sorted_tree = sorted(list(zip(max_depth_value, train_acc, test_acc)), key = lambda e:e[2], reverse = True)\n",
    "\n",
    "print('Top 5 results, sorted by test accuracy:\\n   (Values: depth, training accracy, test accuracy)\\n')\n",
    "print(*combinations_sorted_tree[0:5], sep = \"\\n\")\n",
    "\n",
    "# save the best variable\n",
    "tree_best_max_depth = combinations_sorted_tree[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.6.1 Decision Tree - Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the parameters which want to test for the decision tree model\n",
    "param_grid = {'criterion':['gini','entropy'],'max_depth':[1,2,3,4,5,6,7,8,9,10,12,15,20]}\n",
    "\n",
    "#We make the model with cross validation and grid search\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10)\n",
    "\n",
    "#We fit the model, with the best parameters: \n",
    "gs_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print the results: \n",
    "\n",
    "print(\n",
    "    \"\\n Training score: \", gs_result.best_score_, \n",
    "    \"\\n Best estimator: \", gs_result.best_estimator_,\n",
    "    \"\\n best parameters: \", gs_result.best_params_,\n",
    "    \"Test score: \", grid_search.score(X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Play around with Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "max_depth_value = []\n",
    "criterion_value = []\n",
    "max_features_value = []\n",
    "\n",
    "criterions = ('gini', 'entropy')\n",
    "number_of_features = range(1,6)\n",
    "\n",
    "for i in range(1,9):\n",
    "    for c in criterions:\n",
    "        for f in number_of_features:\n",
    "                rf = RandomForestClassifier(criterion = c, max_depth = i, max_features = f, random_state=0)\n",
    "                rf.fit(X_train, y_train)\n",
    "                train_acc.append(accuracy_score(rf.predict(X_train), y_train))\n",
    "                test_acc.append(accuracy_score(rf.predict(X_test), y_test))\n",
    "                max_depth_value.append(i)\n",
    "                criterion_value.append(c)\n",
    "                max_features_value.append(f)\n",
    "\n",
    "combinations_sorted_forest = sorted(list(zip(max_features_value, criterion_value, max_depth_value, train_acc, test_acc)), key = lambda e:e[3], reverse = True)\n",
    "\n",
    "print('Top 5 results, sorted by test accuracy:\\n   (Values: depth, training accracy, test accuracy)\\n')\n",
    "print(*combinations_sorted_forest[0:5], sep = \"\\n\")\n",
    "\n",
    "# save the best variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest - Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the parameters which want to test for the decision tree model\n",
    "param_grid = {\n",
    "    \"max_features\":[2,4,6,8,10,12,20,40], 'max_depth':[1,2,3,4,5,6,7,8,9,10,12,15,20], \"criterion\":['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "#We make the model with cross validation and grid search\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=10)\n",
    "\n",
    "#We fit the model, with the best parameters: \n",
    "gs_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print the results: \n",
    "\n",
    "print(\n",
    "    \"\\n Training score: \", gs_result.best_score_, \n",
    "    \"\\n Best estimator: \", gs_result.best_estimator_,\n",
    "    \"\\n best parameters: \", gs_result.best_params_,\n",
    "    \"Test score: \", grid_search.score(X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Look at the best combinations with each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN:', combinations_sorted_knn[0])\n",
    "print('Neural Network:', combinations_sorted_mpl[0])\n",
    "print('Decision Tree:', combinations_sorted_tree[0])\n",
    "print('Random Forest:', combinations_sorted_forest[0])\n",
    "\n",
    "best_combos = {'kNN': combinations_sorted_knn[0][-1], 'Neural Network': combinations_sorted_mpl[0][-1], 'Decision Tree': combinations_sorted_tree[0][-1], 'Random Forest': combinations_sorted_forest[0][-1]}\n",
    "# for now, the KNN model has the highest test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(best_combos.keys())\n",
    "# get values in the same order as keys, and parse percentage values\n",
    "vals = [float(best_combos[k]) for k in keys]\n",
    "\n",
    "splot = sns.barplot(x = keys, y = vals, palette = ['Grey', 'Red', 'Grey', 'Grey'])\n",
    "\n",
    "for p in splot.patches:\n",
    "    splot.annotate(format(p.get_height(), '.4f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'top', \n",
    "                   xytext = (0, 9), \n",
    "                   textcoords = 'offset points')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
